<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2019-10-02">

<title>cudawarped - Accelerating OpenCV with Python and CUDA streams</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../imgs/profile_1-e1674474909304.webp" rel="icon">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<meta property="og:title" content="cudawarped - Accelerating OpenCV with Python and CUDA streams">
<meta property="og:description" content="">
<meta property="og:image" content="https://raw.githubusercontent.com/cudawarped/opencv-experiments/master/nbs/imgs/nvprof_1.PNG">
<meta property="og:site-name" content="cudawarped">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a href="../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../imgs\profile_1-e1674474909304.webp" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">cudawarped</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" rel="" target="" aria-current="page">
 <span class="menu-text">OpenCV</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
    <a href="https://github.com/cudawarped" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-github"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../nbs/opencv4-cuda-streams.html">Accelerate with CUDA streams in Python</a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">OpenCV Guides</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../accelerate_opencv_cuda_python.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Build with CUDA and Python on Windows</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../nbs/opencv4-cuda-streams.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Accelerate with CUDA streams in Python</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../opencv_cuda_performance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CUDA Performance Comparisson</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction">Introduction</a>
  <ul class="collapse">
  <li><a href="#initialization" id="toc-initialization" class="nav-link" data-scroll-target="#initialization">Initialization</a></li>
  </ul></li>
  <li><a href="#base-implementations" id="toc-base-implementations" class="nav-link" data-scroll-target="#base-implementations">Base implementations</a>
  <ul class="collapse">
  <li><a href="#cpu" id="toc-cpu" class="nav-link" data-scroll-target="#cpu">CPU</a></li>
  <li><a href="#gpu" id="toc-gpu" class="nav-link" data-scroll-target="#gpu">GPU</a>
  <ul class="collapse">
  <li><a href="#analysis" id="toc-analysis" class="nav-link" data-scroll-target="#analysis">Analysis</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#pre-allocation-of-return-arrays" id="toc-pre-allocation-of-return-arrays" class="nav-link" data-scroll-target="#pre-allocation-of-return-arrays">Pre-allocation of return arrays</a>
  <ul class="collapse">
  <li><a href="#cpu-1" id="toc-cpu-1" class="nav-link" data-scroll-target="#cpu-1">CPU</a></li>
  <li><a href="#gpu-1" id="toc-gpu-1" class="nav-link" data-scroll-target="#gpu-1">GPU</a></li>
  <li><a href="#analysis-1" id="toc-analysis-1" class="nav-link" data-scroll-target="#analysis-1">Analysis</a></li>
  </ul></li>
  <li><a href="#replacing-the-default-stream" id="toc-replacing-the-default-stream" class="nav-link" data-scroll-target="#replacing-the-default-stream">Replacing the default stream</a>
  <ul class="collapse">
  <li><a href="#analysis-2" id="toc-analysis-2" class="nav-link" data-scroll-target="#analysis-2">Analysis</a></li>
  </ul></li>
  <li><a href="#overlap-host-and-device-computation-1" id="toc-overlap-host-and-device-computation-1" class="nav-link" data-scroll-target="#overlap-host-and-device-computation-1">Overlap host and device computation (1)</a>
  <ul class="collapse">
  <li><a href="#analysis-3" id="toc-analysis-3" class="nav-link" data-scroll-target="#analysis-3">Analysis</a></li>
  </ul></li>
  <li><a href="#overlap-host-and-device-computation-2" id="toc-overlap-host-and-device-computation-2" class="nav-link" data-scroll-target="#overlap-host-and-device-computation-2">Overlap host and device computation (2)</a>
  <ul class="collapse">
  <li><a href="#analysis-4" id="toc-analysis-4" class="nav-link" data-scroll-target="#analysis-4">Analysis</a></li>
  </ul></li>
  <li><a href="#overlap-host-and-device-computation-3" id="toc-overlap-host-and-device-computation-3" class="nav-link" data-scroll-target="#overlap-host-and-device-computation-3">Overlap host and device computation (3)</a>
  <ul class="collapse">
  <li><a href="#analysis-5" id="toc-analysis-5" class="nav-link" data-scroll-target="#analysis-5">Analysis</a></li>
  </ul></li>
  <li><a href="#overlap-host-and-device-computation---multiple-streams" id="toc-overlap-host-and-device-computation---multiple-streams" class="nav-link" data-scroll-target="#overlap-host-and-device-computation---multiple-streams">Overlap host and device computation - multiple streams</a>
  <ul class="collapse">
  <li><a href="#analysis-6" id="toc-analysis-6" class="nav-link" data-scroll-target="#analysis-6">Analysis</a></li>
  </ul></li>
  <li><a href="#timing-without-the-profiler" id="toc-timing-without-the-profiler" class="nav-link" data-scroll-target="#timing-without-the-profiler">Timing without the profiler</a>
  <ul class="collapse">
  <li><a href="#analysis-7" id="toc-analysis-7" class="nav-link" data-scroll-target="#analysis-7">Analysis</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary">Summary</a>
  <ul class="collapse">
  <li><a href="#run-outside-the-notebook" id="toc-run-outside-the-notebook" class="nav-link" data-scroll-target="#run-outside-the-notebook">Run outside the notebook</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/cudawarped/opencv-experiments/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Accelerating OpenCV with Python and CUDA streams</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button" data-quarto-source-url="https://github.com/cudawarped/opencv-experiments/blob/master/nbs/opencv4-cuda-streams.ipynb">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 2, 2019</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="introduction" class="level1">
<h1>Introduction</h1>
<p>Since Aug 2018 the OpenCV CUDA API has been exposed to python. To get the most from this new functionality you need to have a basic understanding of CUDA (most importantly that it is <a href="https://en.wikipedia.org/wiki/Data_parallelism">data</a> not <a href="https://en.wikipedia.org/wiki/Task_parallelism">task</a> parallel) and its interaction with OpenCV. Below I have tried to introduce these topics with an example of how you could optimize a toy video processing pipeline. The actual functions called in the pipeline are not important, they are simply there to simulate a common processing pipeline consisting of work performed on both the host (CPU) and device (GPU).</p>
<p>This guide is taken from a <a href="https://jupyter.org/">Jupyter Notebook</a> which can be cloned from <a href="https://github.com/cudawarped/opencv-experiments/blob/master/nbs/opencv4-cuda-streams.ipynb">here</a>. The procedure is as follows, following some quick <a href="#initialization">initialization</a>, we start with a <a href="#base-implementation">base</a> implementation on both the <a href="#cpu_naive">CPU</a> and <a href="#gpu_naive">GPU</a> to get a baseline result. We then proceed to incrementally improve the implementation by using the information provided by the <a href="https://developer.nvidia.com/nvidia-visual-profiler">Nvidia Visual Profiler</a>.</p>
<p>On a laptop RTX 2080 paired with an i7-8700 the final CUDA incarnation resulted in a speed up of ~30x and ~10x over the naive CPU and GPU implementations.</p>
<p>The motivation is to show that if you can understand a few simple concepts</p>
<p>The idea is to help uses of the OpenCV CUDA modules get the most performance</p>
<p>By using Python I hope to show that its possible for even</p>
<p>The idea is to show t</p>
<p>By the end of the guide I hope that 1) I will have shown that even when calling OpenCV from Python its possible to fully saturate your GPU and hopefully 2) Demonstrated that even though getting the maximum performance gains when switching from using the host to the GPU</p>
<p>the OpenCV CUDA modules</p>
<p>how to get the most performance from the OpenCV</p>
<section id="initialization" class="level2">
<h2 class="anchored" data-anchor-id="initialization">Initialization</h2>
<div class="cell" data-execution_count="1">
<details>
<summary>Expand for initialization parameters</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> cv2 <span class="im">as</span> cv</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>vidPath <span class="op">=</span> os.environ[<span class="st">'OPENCV_TEST_DATA_PATH'</span>] <span class="op">+</span> <span class="st">'/cv/video/768x576.avi'</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.05</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>rows_big <span class="op">=</span> <span class="dv">1440</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>cols_big <span class="op">=</span> <span class="dv">2560</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>check_res <span class="op">=</span> <span class="va">False</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>frame_device <span class="op">=</span> cv.cuda_GpuMat()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><a id="naive"></a></p>
</section>
</section>
<section id="base-implementations" class="level1 page-columns page-full">
<h1>Base implementations</h1>
<p>This implementation simply loops through all the frames in the source video passing them through the video processing pipeline without considering any optimization steps. Because the video is decoded using the CPU the main difference between the CPU and GPU versions is that the frames are uploaded and downloaded to the GPU on every iteration, for details you can expand the code blocks below.</p>
<div class="cell" data-execution_count="57">
<details>
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ProcVid0(proc_frame_func,lr):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    cap <span class="op">=</span> cv.VideoCapture(vidPath)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (cap.isOpened()<span class="op">==</span> <span class="va">False</span>): </span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Error opening video stream or file"</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    n_frames <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span>(cap.isOpened()):</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ret <span class="op">==</span> <span class="va">True</span>:</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            n_frames <span class="op">+=</span> <span class="dv">1</span> </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>            proc_frame_func(frame,lr)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> time.time()</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    cap.release()</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (end <span class="op">-</span> start)<span class="op">*</span><span class="dv">1000</span><span class="op">/</span>n_frames, n_frames<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><a id="cpu_naive"></a></p>
<section id="cpu" class="level2">
<h2 class="anchored" data-anchor-id="cpu">CPU</h2>
<div class="cell" data-execution_count="59">
<details>
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>bgmog2 <span class="op">=</span> cv.createBackgroundSubtractorMOG2()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ProcFrameCPU0(frame,lr,store_res<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    frame_big <span class="op">=</span> cv.resize(frame,(cols_big,rows_big))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    fg_big <span class="op">=</span> bgmog2.<span class="bu">apply</span>(frame_big,learningRate <span class="op">=</span> lr)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    fg_small <span class="op">=</span> cv.resize(fg_big,(frame.shape[<span class="dv">1</span>],frame.shape[<span class="dv">0</span>]))</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(store_res):</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>        cpu_res.append(np.copy(fg_small))</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>cpu_res <span class="op">=</span> []</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>cpu_time_0, n_frames <span class="op">=</span> ProcVid0(partial(ProcFrameCPU0,store_res<span class="op">=</span>check_res),lr)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'CPU 0 (naive): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>cpu_time_0<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>CPU 0 (naive): 100 frames, 30.05 ms/frame</code></pre>
</div>
</div>
<p><a id="gpu_naive"></a></p>
</section>
<section id="gpu" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="gpu">GPU</h2>
<div class="cell" data-execution_count="61">
<details>
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>bgmog2_device <span class="op">=</span> cv.cuda.createBackgroundSubtractorMOG2()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ProcFrameCuda0(frame,lr,store_res<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    frame_device.upload(frame)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    frame_device_big <span class="op">=</span> cv.cuda.resize(frame_device,(cols_big,rows_big))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    fg_device_big <span class="op">=</span> bgmog2_device.<span class="bu">apply</span>(frame_device_big,lr,cv.cuda.Stream_Null())</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    fg_device <span class="op">=</span> cv.cuda.resize(fg_device_big,frame_device.size())</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    fg_host <span class="op">=</span> fg_device.download()</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(store_res):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        gpu_res.append(np.copy(fg_host))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>gpu_res <span class="op">=</span> []</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>gpu_time_0, n_frames <span class="op">=</span> ProcVid0(partial(ProcFrameCuda0,store_res<span class="op">=</span>check_res),lr)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'GPU 0 (naive): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>gpu_time_0<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over CPU: </span><span class="sc">{</span>cpu_time_0<span class="op">/</span>gpu_time_0<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>GPU 0 (naive): 100 frames, 3.92 ms/frame
Speedup over CPU: 7.67</code></pre>
</div>
</div>
<p><a id="analysis_0"></a></p>
<section id="analysis" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="analysis">Analysis</h3>
<div class="column-screen">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/cudawarped/opencv-experiments/master/nbs/imgs/nvprof_1.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">gpu_naive</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The output <code>gpu_time_0</code> from above is the average amount of time to process each frame, recorded on the host. This will be referred to as the frame time and is the value that we want to reduce. In order to achieve this we need to investigate what is actually occurring on the host and device for each frame. Luckily the Nvidia provides a useful visual tool for this, the <a href="https://developer.nvidia.com/nvidia-visual-profiler">Nvidia Visual Profiler</a>.</p>
<p>The image above shows the Nvidia Visual Profiler output from processing 2 of the 100 frames. Important things to be aware of here are:</p>
<ol type="1">
<li>The runtime API calls in brown which in this example represent the time the host (CPU) spends waiting for the device (GPU) calls to return.</li>
<li>The remaining blocks which show the time spent on the device. This is split according to the operation (kernel, memset, MemCpy(HtoD), MemCpy(DtoH)) as well as by the CUDA stream which the operations are issued to. In this case everything is issued to the Default stream.</li>
<li>The 0.93ms gap in between the blocks of runtime API calls represents the time spent executing code on the host, here that is the time taken for OpenCV to read and decode each video frame, <code>frame = cap.read()</code>.</li>
<li>In this naive implementation all device calls from the host are synchronous and as a result the difference between (1) and (2) can be interpreted as periods where no useful work is being performed on either the host or the device. The host is blocking waiting for the device to return and the device is also idle, allocating or freeing memory.</li>
</ol>
<p><strong>From now on for convenience, for a single frame, I will refer to 1), 2) and 3) as the runtime API time, device time, host time respectively. As shown the profiler output, the current runtime API time and host time are ~2.38ms and ~0.93ms.</strong></p>
<p>Taking (1) and (4) into account from left to right the output from the profiler can be mapped to the python calls as:</p>
<ul>
<li>(1217.62ms-1220ms) <code>proc_frame_func(frame,lr)</code>: calls to the device to process the first frame (<strong>~2.38ms</strong>)</li>
<li>(1220ms-1220.93ms) <code>frame = cap.read()</code>: read and decode the second video frame on the host (<strong>~0.93ms</strong>)</li>
<li>(1220.93ms-) <code>proc_frame_func(frame,lt)</code>: calls to the device to process the second frame</li>
</ul>
<p>Clearly from the gaps described in (4) a lot of time is wasted waiting for the device calls to return, and as the host time does not overlap the device time, there is a lot of room for improvement.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypothesis
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The main causes of (4) are the blocking calls to both</p>
<ul>
<li><p><code>cudaMallocPitch()</code> - OpenCV in python automatically allocates any arrays (NumPy or <code>GpuMat</code>) which are returned from a function call. That is on every iteration</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>ret, frame <span class="op">=</span> cap.read()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>causes memory for the NumPy array <code>frame</code> to be allocated and destroyed on the host and</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>frame_device_big <span class="op">=</span> cv.cuda.resize(frame_device,(cols_big,rows_big))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>fg_device_big <span class="op">=</span> bgmog2_device.<span class="bu">apply</span>(frame_device_big,lr,cv.cuda.Stream_Null())</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>fg_device <span class="op">=</span> cv.cuda.resize(fg_device_big,frame_device.size())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>causes memory for <code>frame_device_big</code>, <code>fg_device_big</code> and <code>fg_device</code> to be allocated and destroyed on the device.</p></li>
<li><p><code>cudaDeviceSynchronise()</code> - if you don’t explicitly pass in a CUDA stream to an OpenCV CUDA function, the default stream will be used and <code>cudaDeviceSynchronize()</code> will be called before the function exits, stalling the GPU every time.</p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Address the unnecessary calls to <code>cudaMallocPitch()</code>, by pre-allocating any output arrays and passing them as input arguments.</p>
</div>
</div>
</div>
<p><a id="pre_allocation"></a></p>
</section>
</section>
</section>
<section id="pre-allocation-of-return-arrays" class="level1 page-columns page-full">
<h1>Pre-allocation of return arrays</h1>
<p>The only difference between this and the base implementation is that all of the return arrays are pre-allocated and passed to the Python functions. e.g.&nbsp;instead of</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>frame_device_big <span class="op">=</span> cv.cuda.resize(frame_device,(cols_big,rows_big))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>the memory for <code>self.frame_device</code> is pre-allocated in the constructor</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.frame_device <span class="op">=</span> cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>and passed to <code>cv.cuda.resize</code></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>cv.cuda.resize(<span class="va">self</span>.frame_device,(cols_big,rows_big),<span class="va">self</span>.frame_device_big)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell" data-execution_count="62">
<details>
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ProcVid1(proc_frame,lr):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    cap <span class="op">=</span> cv.VideoCapture(vidPath)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (cap.isOpened()<span class="op">==</span> <span class="va">False</span>): </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Error opening video stream or file"</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    n_frames <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span>(cap.isOpened()):</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>        ret,_ <span class="op">=</span> cap.read(proc_frame.Frame())</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ret <span class="op">==</span> <span class="va">True</span>:</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>            n_frames <span class="op">+=</span> <span class="dv">1</span> </span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>            proc_frame.ProcessFrame(lr)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> time.time()</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    cap.release()</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (end <span class="op">-</span> start)<span class="op">*</span><span class="dv">1000</span><span class="op">/</span>n_frames, n_frames<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p><a id="cpu_1"></a></p>
<section id="cpu-1" class="level2">
<h2 class="anchored" data-anchor-id="cpu-1">CPU</h2>
<div class="cell" data-execution_count="65">
<details>
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProcFrameCpu1:</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,rows_small,cols_small,rows_big,cols_big,store_res<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rows_small, <span class="va">self</span>.cols_small, <span class="va">self</span>.rows_big, <span class="va">self</span>.cols_big <span class="op">=</span> rows_small,cols_small,rows_big,cols_big</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.store_res <span class="op">=</span> store_res</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res <span class="op">=</span> []</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2 <span class="op">=</span> cv.createBackgroundSubtractorMOG2()</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame <span class="op">=</span> np.empty((rows_small,cols_small,<span class="dv">3</span>),np.uint8)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_big <span class="op">=</span> np.empty((rows_big,cols_big,<span class="dv">3</span>),np.uint8)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_big <span class="op">=</span> np.empty((rows_big,cols_big),np.uint8)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_small <span class="op">=</span> np.empty((rows_small,cols_small),np.uint8)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ProcessFrame(<span class="va">self</span>,lr):</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>        cv.resize(<span class="va">self</span>.frame,(<span class="va">self</span>.cols_big,<span class="va">self</span>.rows_big),<span class="va">self</span>.frame_big)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2.<span class="bu">apply</span>(<span class="va">self</span>.frame_big,<span class="va">self</span>.fg_big,learningRate <span class="op">=</span> lr)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>        cv.resize(<span class="va">self</span>.fg_big,(<span class="va">self</span>.cols_small,<span class="va">self</span>.rows_small),<span class="va">self</span>.fg_small)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fg_small))</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Frame(<span class="va">self</span>):</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.frame</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>cap <span class="op">=</span> cv.VideoCapture(vidPath)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (cap.isOpened()<span class="op">==</span> <span class="va">False</span>): </span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>  <span class="bu">print</span>(<span class="st">"Error opening video stream or file"</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>ret, frame <span class="op">=</span> cap.read()</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>cap.release()</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>rows_small,cols_small <span class="op">=</span> frame.shape[:<span class="dv">2</span>]</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>proc_frame_cpu1 <span class="op">=</span> ProcFrameCpu1(rows_small,cols_small,rows_big,cols_big,check_res)</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>cpu_time_1, n_frames <span class="op">=</span> ProcVid1(proc_frame_cpu1,lr)</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'CPU 1 (pre-allocation): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>cpu_time_1<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over CPU baseline: </span><span class="sc">{</span>cpu_time_0<span class="op">/</span>cpu_time_1<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>CPU 1 (pre-allocation): 100 frames, 27.76 ms/frame
Speedup over CPU baseline: 1.08</code></pre>
</div>
</div>
<p><a id="gpu_1"></a></p>
</section>
<section id="gpu-1" class="level2">
<h2 class="anchored" data-anchor-id="gpu-1">GPU</h2>
<div class="cell" data-scrolled="true" data-execution_count="68">
<details>
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProcFrameCuda1:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,rows_small,cols_small,rows_big,cols_big,store_res<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rows_small, <span class="va">self</span>.cols_small, <span class="va">self</span>.rows_big, <span class="va">self</span>.cols_big <span class="op">=</span> rows_small,cols_small,rows_big,cols_big</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.store_res <span class="op">=</span> store_res</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res <span class="op">=</span> []</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2 <span class="op">=</span> cv.cuda.createBackgroundSubtractorMOG2()</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame <span class="op">=</span> np.empty((rows_small,cols_small,<span class="dv">3</span>),np.uint8)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device <span class="op">=</span> cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)        </span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device_big.setTo(<span class="dv">0</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device <span class="op">=</span> cv.cuda_GpuMat(np.shape(frame)[<span class="dv">0</span>],np.shape(frame)[<span class="dv">1</span>],cv.CV_8UC1)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_host <span class="op">=</span> np.empty((rows_small,cols_small),np.uint8)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ProcessFrame(<span class="va">self</span>,lr):</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device.upload(<span class="va">self</span>.frame)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.frame_device,(cols_big,rows_big),<span class="va">self</span>.frame_device_big)</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2.<span class="bu">apply</span>(<span class="va">self</span>.frame_device_big,lr,cv.cuda.Stream_Null(),<span class="va">self</span>.fg_device_big)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.fg_device_big,<span class="va">self</span>.fg_device.size(),<span class="va">self</span>.fg_device)</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device.download(<span class="va">self</span>.fg_host)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fg_host))</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Frame(<span class="va">self</span>):</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.frame</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>proc_frame_cuda1 <span class="op">=</span> ProcFrameCuda1(rows_small,cols_small,rows_big,cols_big,check_res)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>gpu_time_1, n_frames <span class="op">=</span> ProcVid1(proc_frame_cuda1,lr)</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'GPU 1 (pre-allocation): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>gpu_time_1<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Incremental speedup: </span><span class="sc">{</span>gpu_time_0<span class="op">/</span>gpu_time_1<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over CPU: </span><span class="sc">{</span>cpu_time_1<span class="op">/</span>gpu_time_1<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>GPU 1 (pre-allocation): 100 frames, 1.99 ms/frame
Incremental speedup: 1.96
Speedup over CPU: 13.91</code></pre>
</div>
</div>
<p><a id="analysis_1"></a></p>
</section>
<section id="analysis-1" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="analysis-1">Analysis</h2>
<div class="column-screen">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/cudawarped/opencv-experiments/master/nbs/imgs/nvprof_2.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">title</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Pre-allocating the arrays has successfully removed the calls to <code>cudaMallocPitch()</code> and significantly (3 frames are now processed instead of 1.5) reduced (4), the time the host spends waiting for the CUDA runtime to return control to it.</p>
<p>Pre-allocation on the host has also reduced the host time from ~0.93ms to ~0.57ms. The host time will now be unaffected by the remaining changes we make and can be observed to be approximately constant after each of the following optimizations.</p>
<p>We will now proceed to try and reduce the runtime API time which in this step has already been fallen from ~2.38ms to ~1.15ms.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypothesis
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>As mentioned above by not specifying a stream all calls are placed in the <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html">“Default”</a> stream which can be seen at the bottom of the figure. This means that following each asynchronous kernel launch there will be a synchronizing call to <code>cudaDeviceSynchronize()</code> shown below:</p>
<div class="sourceCode" id="annotated-cell-1"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-1-1" class="code-annotation-target"><a href="#annotated-cell-1-1" aria-hidden="true" tabindex="-1"></a>cv.cuda.resize(frame_device,(cols_big,rows_big),frame_device_big)</span>
<span id="annotated-cell-1-2"><a href="#annotated-cell-1-2" aria-hidden="true" tabindex="-1"></a>cudaDeviceSynchronize()</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-1-3" class="code-annotation-target"><a href="#annotated-cell-1-3" aria-hidden="true" tabindex="-1"></a>bgmog2_device.<span class="bu">apply</span>(frame_device_big,lr,cv.cuda.Stream_Null(),fg_device_big)</span>
<span id="annotated-cell-1-4"><a href="#annotated-cell-1-4" aria-hidden="true" tabindex="-1"></a>cudaDeviceSynchronize()</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="3" onclick="event.preventDefault();">3</a><span id="annotated-cell-1-5" class="code-annotation-target"><a href="#annotated-cell-1-5" aria-hidden="true" tabindex="-1"></a>cv.cuda.resize(fg_device_big,fg_device.size(),fg_device)</span>
<span id="annotated-cell-1-6"><a href="#annotated-cell-1-6" aria-hidden="true" tabindex="-1"></a>cudaDeviceSynchronize()</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="4" onclick="event.preventDefault();">4</a><span id="annotated-cell-1-7" class="code-annotation-target"><a href="#annotated-cell-1-7" aria-hidden="true" tabindex="-1"></a>fg_device.download(fg_host)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-1" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="1" data-code-annotation="1">asynchronous kernel 1</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="2">2</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="3" data-code-annotation="2">asynchronous kernel 2</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="3">3</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="5" data-code-annotation="3">asynchronous kernel 3</span>
</dd>
<dt data-target-cell="annotated-cell-1" data-target-annotation="4">4</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="7" data-code-annotation="4">synchronous copy from device to host</span>
</dd>
</dl>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Pass a non default CUDA stream to each OpenCV CUDA function.</p>
</div>
</div>
</div>
<p><a id="streams"></a></p>
<p><a id="gpu_2"></a></p>
</section>
</section>
<section id="replacing-the-default-stream" class="level1 page-columns page-full">
<h1>Replacing the default stream</h1>
<p>Each cuda function is now passed a CUDA stream to work in which should prevent calls to <code>cudaDeviceSynchronize()</code> afteer every function and we have a single call after all functions to <code>self.stream.waitForCompletion()</code> which replaces previous call to<code>cudaDeviceSynchronize()</code></p>
<p>We have replaced the implicit call to <code>cudaDeviceSynchronize()</code> after every function call with a single call to <code>self.stream.waitForCompletion()</code> after the last function in the pipeline.</p>
<div class="cell" data-execution_count="71">
<details>
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProcFrameCuda2:</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,rows_small,cols_small,rows_big,cols_big,store_res<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rows_small, <span class="va">self</span>.cols_small, <span class="va">self</span>.rows_big, <span class="va">self</span>.cols_big <span class="op">=</span> rows_small,cols_small,rows_big,cols_big</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.store_res <span class="op">=</span> store_res</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res <span class="op">=</span> []</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2 <span class="op">=</span> cv.cuda.createBackgroundSubtractorMOG2()</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream <span class="op">=</span> cv.cuda_Stream()</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame <span class="op">=</span> np.empty((rows_small,cols_small,<span class="dv">3</span>),np.uint8)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device <span class="op">=</span> cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device <span class="op">=</span> cv.cuda_GpuMat(np.shape(frame)[<span class="dv">0</span>],np.shape(frame)[<span class="dv">1</span>],cv.CV_8UC1)</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_host <span class="op">=</span> np.empty((rows_small,cols_small),np.uint8)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ProcessFrame(<span class="va">self</span>,lr):</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device.upload(<span class="va">self</span>.frame,<span class="va">self</span>.stream)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.frame_device,(cols_big,rows_big),<span class="va">self</span>.frame_device_big,stream<span class="op">=</span><span class="va">self</span>.stream)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2.<span class="bu">apply</span>(<span class="va">self</span>.frame_device_big,lr,<span class="va">self</span>.stream,<span class="va">self</span>.fg_device_big)</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.fg_device_big,<span class="va">self</span>.fg_device.size(),<span class="va">self</span>.fg_device,stream<span class="op">=</span><span class="va">self</span>.stream)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device.download(<span class="va">self</span>.stream,<span class="va">self</span>.fg_host)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream.waitForCompletion()  <span class="co"># imidiate wait</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fg_host))</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Frame(<span class="va">self</span>):</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.frame</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>proc_frame_cuda2 <span class="op">=</span> ProcFrameCuda2(rows_small,cols_small,rows_big,cols_big,check_res)</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>gpu_time_2, n_frames <span class="op">=</span> ProcVid1(proc_frame_cuda2,lr)</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'GPU 2 (replacing the default stream): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>gpu_time_2<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Incremental speedup: </span><span class="sc">{</span>gpu_time_1<span class="op">/</span>gpu_time_2<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over GPU baseline: </span><span class="sc">{</span>gpu_time_0<span class="op">/</span>gpu_time_2<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over CPU: </span><span class="sc">{</span>cpu_time_1<span class="op">/</span>gpu_time_2<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>GPU 2 (replacing the default stream): 100 frames, 1.90 ms/frame
Incremental speedup: 1.05
Speedup over GPU baseline: 2.07
Speedup over CPU: 14.64</code></pre>
</div>
</div>
<p><a id="analysis_2"></a></p>
<section id="analysis-2" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="analysis-2">Analysis</h2>
<div class="column-screen">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/cudawarped/opencv-experiments/master/nbs/imgs/nvprof_3.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">title</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The calls to <code>cudaDeviceSyncronize()</code> have now been removed, and as a result the gaps between the device calls have disappeared, further reducing the runtime API time from ~1.15ms to ~1.07ms. That said it looks like the calls to <code>cudaDeviceSyncronize()</code> have just been replaced by calls to <code>cudaMemcpy2DAsync()</code>.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypothesis
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>As mentioned above by not specifying a stream all calls are placed in the <a href="https://docs.nvidia.com/cuda/cuda-runtime-api/stream-sync-behavior.html">“Default”</a> stream which can be seen at the bottom of the figure. This means that following each asynchronous kernel launch there will be a synchronizing call to <code>cudaDeviceSynchronize()</code> shown below:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>cv.cuda.resize(frame_device,(cols_big,rows_big),frame_device_big)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>cudaDeviceSynchronize()</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>bgmog2_device.<span class="bu">apply</span>(frame_device_big,lr,cv.cuda.Stream_Null(),fg_device_big)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>cudaDeviceSynchronize()</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>cv.cuda.resize(fg_device_big,fg_device.size(),fg_device)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>cudaDeviceSynchronize()</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>fg_device.download(fg_host)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Pin the host memory.</p>
</div>
</div>
</div>
<p><a id="gpu_3"></a></p>
</section>
</section>
<section id="overlap-host-and-device-computation-1" class="level1 page-columns page-full">
<h1>Overlap host and device computation (1)</h1>
<div class="cell" data-execution_count="73">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># host mem not implemented, manually pin memory</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PinnedMem(<span class="bu">object</span>):</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, size, dtype<span class="op">=</span>np.uint8):</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.array <span class="op">=</span> np.empty(size,dtype)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>        cv.cuda.registerPageLocked(<span class="va">self</span>.array)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pinned <span class="op">=</span> <span class="va">True</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__del__</span>(<span class="va">self</span>):</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>        cv.cuda.unregisterPageLocked(<span class="va">self</span>.array)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pinned <span class="op">=</span> <span class="va">False</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__repr__</span>(<span class="va">self</span>):</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="ss">f'pinned = </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>pinned<span class="sc">}</span><span class="ss">'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="74">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProcFrameCuda3:</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,rows_small,cols_small,rows_big,cols_big,store_res<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rows_small, <span class="va">self</span>.cols_small, <span class="va">self</span>.rows_big, <span class="va">self</span>.cols_big <span class="op">=</span> rows_small,cols_small,rows_big,cols_big</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.store_res <span class="op">=</span> store_res</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res <span class="op">=</span> []</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2 <span class="op">=</span> cv.cuda.createBackgroundSubtractorMOG2()</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream <span class="op">=</span> cv.cuda_Stream()</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame <span class="op">=</span> PinnedMem((rows_small,cols_small,<span class="dv">3</span>))</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device <span class="op">=</span> cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device <span class="op">=</span> cv.cuda_GpuMat(np.shape(frame)[<span class="dv">0</span>],np.shape(frame)[<span class="dv">1</span>],cv.CV_8UC1)</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_host <span class="op">=</span> PinnedMem((rows_small,cols_small))</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ProcessFrame(<span class="va">self</span>,lr):</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device.upload(<span class="va">self</span>.frame.array,<span class="va">self</span>.stream)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.frame_device,(cols_big,rows_big),<span class="va">self</span>.frame_device_big,stream<span class="op">=</span><span class="va">self</span>.stream)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2.<span class="bu">apply</span>(<span class="va">self</span>.frame_device_big,lr,<span class="va">self</span>.stream,<span class="va">self</span>.fg_device_big)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.fg_device_big,<span class="va">self</span>.fg_device.size(),<span class="va">self</span>.fg_device,stream<span class="op">=</span><span class="va">self</span>.stream)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device.download(<span class="va">self</span>.stream,<span class="va">self</span>.fg_host.array)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream.waitForCompletion() <span class="co"># imidiate wait</span></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fg_host.array))</span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Frame(<span class="va">self</span>):</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.frame.array</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>proc_frame_cuda3 <span class="op">=</span> ProcFrameCuda3(rows_small,cols_small,rows_big,cols_big,check_res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="75">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>gpu_time_3, n_frames <span class="op">=</span> ProcVid1(proc_frame_cuda3,lr)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'GPU 3 (overlap host and device - attempt 1): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>gpu_time_3<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Incremental speedup: </span><span class="sc">{</span>gpu_time_2<span class="op">/</span>gpu_time_3<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over GPU baseline: </span><span class="sc">{</span>gpu_time_0<span class="op">/</span>gpu_time_3<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over CPU: </span><span class="sc">{</span>cpu_time_1<span class="op">/</span>gpu_time_3<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>GPU 3 (overlap host and device - attempt 1): 100 frames, 1.83 ms/frame
Incremental speedup: 1.04
Speedup over GPU baseline: 2.14
Speedup over CPU: 15.15</code></pre>
</div>
</div>
<p><a id="analysis_3"></a></p>
<section id="analysis-3" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="analysis-3">Analysis</h2>
<div class="column-screen">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/cudawarped/opencv-experiments/master/nbs/imgs/nvprof_4.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">title</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The output is now more intuitive, that said all that we have done is replace the calls to <code>cudaDeviceSyncronize()</code> with calls to <code>cudaStreamSyncronize()</code>.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypothesis
</div>
</div>
<div class="callout-body-container callout-body">
<p>We are issuing asynchronous calls to the device and then immediately waiting on the host for them to complete.</p>
<blockquote class="blockquote">
<p><code>cv.cuda.resize(frame_device,(cols_big,rows_big),frame_device_big,stream=stream)</code> async kernel 1<br> <code>bgmog2.apply(frame_device_big,lr,stream,fg_device_big)</code> async kernel 2<br> <code>cv.cuda.resize(fg_device_big,fg_device.size(),fg_device,stream=stream)</code> acync kernel 3<br> <code>fg_device.download(stream,fg_host.array)</code> async copy DtoH<br> <code>stream.waitForCompletion()</code> block until kernel 1-3 and copy have finished</p>
</blockquote>
<p>What we really want to do is overlap host and device computation by issuing asynchronous calls to the device and then performing processing on the host, before waiting for the asynchronous device calls to return. For two frames this would be:</p>
<blockquote class="blockquote">
<p><code>frame_device.upload(frame[0].array,stream)</code> async copy HtoD, frame 0<br> <code>cv.cuda.resize(frame_device,(n_cols_big,n_rows_big),frame_device_big,stream=stream)</code> async kernel 1, frame 0 <br> <code>bgmog2.apply(frame_device_big,lr,stream,fg_device_big)</code> async kernel 2, frame 0<br> <code>cv.cuda.resize(fg_device_big,fg_device.size(),fg_device,stream=stream)</code> acync kernel 3, frame 0<br> <code>fg_device.download(stream,fg_host.array)</code> async copy DtoH, frame 0<br> <code>ret,_ = cap.read(frame[1].array)</code> host read frame 1 <br> <code>stream.waitForCompletion()</code> <strong>block until kernel 1-3 and copy have finished for frame 0</strong></p>
</blockquote>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Move the position of the synchronization point to after a new frame has been read as described above. To do this We also need to increase the number of host frame containers to two because moving the sync point means frame 0 may still be in the process of being uploaded to the device when we read frame 1. That is, when we call</p>
<blockquote class="blockquote">
<p><code>ret,_ = cap.read(frame[1].array)</code> we have not synced, and we have no way to know if the previous call to <code>frame_device.upload(frame[0].array,stream)</code> has finished, hence we need to write to <code>frame[1].array</code> <br></p>
</blockquote>
</div>
</div>
</div>
<p><a id="gpu_4"></a></p>
</section>
</section>
<section id="overlap-host-and-device-computation-2" class="level1 page-columns page-full">
<h1>Overlap host and device computation (2)</h1>
<div class="cell" data-execution_count="77">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> ProcVid2(proc_frame,lr,simulate<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    cap <span class="op">=</span> cv.VideoCapture(vidPath)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (cap.isOpened()<span class="op">==</span> <span class="va">False</span>): </span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Error opening video stream or file"</span>)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    n_frames <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    start <span class="op">=</span> time.time()    </span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span>(cap.isOpened()):</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        ret,_ <span class="op">=</span> cap.read(proc_frame.Frame())</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> ret <span class="op">==</span> <span class="va">True</span>:</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>            n_frames <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="kw">not</span> simulate:</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>                proc_frame.ProcessFrame(lr)</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    proc_frame.Sync()</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    end <span class="op">=</span> time.time()    </span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    cap.release()</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (end <span class="op">-</span> start)<span class="op">*</span><span class="dv">1000</span><span class="op">/</span>n_frames, n_frames<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="78">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProcFrameCuda4:</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,rows_small,cols_small,rows_big,cols_big,store_res<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rows_small, <span class="va">self</span>.cols_small, <span class="va">self</span>.rows_big, <span class="va">self</span>.cols_big <span class="op">=</span> rows_small,cols_small,rows_big,cols_big</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.store_res <span class="op">=</span> store_res</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res <span class="op">=</span> []</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2 <span class="op">=</span> cv.cuda.createBackgroundSubtractorMOG2()</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream <span class="op">=</span> cv.cuda_Stream()</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_num <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_writable_mem <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frames_in <span class="op">=</span> [PinnedMem((rows_small,cols_small,<span class="dv">3</span>)),PinnedMem((rows_small,cols_small,<span class="dv">3</span>))]</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device <span class="op">=</span> cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device <span class="op">=</span> cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC1)</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_host <span class="op">=</span> PinnedMem((rows_small,cols_small))</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ProcessFrame(<span class="va">self</span>,lr):</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_num <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.frame_num <span class="op">&gt;</span> <span class="dv">1</span>):</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.stream.waitForCompletion() <span class="co"># wait after we have read the next frame</span></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fg_host.array))</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device.upload(<span class="va">self</span>.frames_in[<span class="va">self</span>.i_writable_mem].array, <span class="va">self</span>.stream)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.frame_device, (cols_big,rows_big), <span class="va">self</span>.frame_device_big, stream<span class="op">=</span><span class="va">self</span>.stream)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2.<span class="bu">apply</span>(<span class="va">self</span>.frame_device_big, lr, <span class="va">self</span>.stream, <span class="va">self</span>.fg_device_big )</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.fg_device_big, <span class="va">self</span>.fg_device.size(), <span class="va">self</span>.fg_device, stream<span class="op">=</span><span class="va">self</span>.stream)</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device.download(<span class="va">self</span>.stream,<span class="va">self</span>.fg_host.array)</span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb25-30"><a href="#cb25-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Frame(<span class="va">self</span>):</span>
<span id="cb25-31"><a href="#cb25-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_writable_mem <span class="op">=</span> (<span class="va">self</span>.i_writable_mem <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="bu">len</span>(<span class="va">self</span>.frames_in)</span>
<span id="cb25-32"><a href="#cb25-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.frames_in[<span class="va">self</span>.i_writable_mem].array</span>
<span id="cb25-33"><a href="#cb25-33" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-34"><a href="#cb25-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Sync(<span class="va">self</span>):</span>
<span id="cb25-35"><a href="#cb25-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream.waitForCompletion()</span>
<span id="cb25-36"><a href="#cb25-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb25-37"><a href="#cb25-37" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fg_host.array))</span>
<span id="cb25-38"><a href="#cb25-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb25-39"><a href="#cb25-39" aria-hidden="true" tabindex="-1"></a>proc_frame_cuda4 <span class="op">=</span> ProcFrameCuda4(rows_small,cols_small,rows_big,cols_big,check_res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-scrolled="true" data-execution_count="79">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>gpu_time_4, n_frames <span class="op">=</span> ProcVid2(proc_frame_cuda4,lr)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'GPU 4 (overlap host and device - attempt 2): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>gpu_time_4<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Incremental speedup: </span><span class="sc">{</span>gpu_time_3<span class="op">/</span>gpu_time_4<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over GPU baseline: </span><span class="sc">{</span>gpu_time_0<span class="op">/</span>gpu_time_4<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over CPU: </span><span class="sc">{</span>cpu_time_1<span class="op">/</span>gpu_time_4<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>GPU 4 (overlap host and device - attempt 2): 100 frames, 1.83 ms/frame
Incremental speedup: 1.00
Speedup over GPU baseline: 2.14
Speedup over CPU: 15.18</code></pre>
</div>
</div>
<p><a id="analysis_4"></a></p>
<section id="analysis-4" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="analysis-4">Analysis</h2>
<div class="column-screen">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/cudawarped/opencv-experiments/master/nbs/imgs/nvprof_5.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">title</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>At first glance changing the synchronization point does not appear to have done anything the <code>cudaStreamSynchronize()</code> (<code>stream.waitForCompletion()</code>) still starts at the point just before the frame is processed on the device. On closer inspection we can see that the runtime API time (~1.5ms) now begins much earlier than the device time (~0.8ms) and as we intended overlaps the host time. That said we are not seeing any host/device processing overlap, so whats going on?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypothesis
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is most likely to be because we are working on Windows where the GPU is a Windows Display Driver Model device. See below for more details.</p>
</div>
</div>
<blockquote class="blockquote">
<p><a href="https://devtalk.nvidia.com/default/topic/548639/is-wddm-causing-this-/">CUDA driver has a software queue for WDDM devices to reduce the average overhead of submitting command buffers to the WDDM KMD driver</a></p>
</blockquote>
<p>This would cause all the device calls from the previous frame to be queued and then issued when we call <code>stream.waitForCompletion()</code> and could explain the profiler output.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Test the hypothesis by forcing the CUDA driver to dispatch all queued calls by issuing a call to <code>stream.queryIfComplete()</code> as shown below.</p>
<blockquote class="blockquote">
<p><code>frame_device.upload(frames_in[0].array, stream)</code> async copy HtoD, frame 0<br> <code>cv.cuda.resize(frame_device,(n_cols_big,n_rows_big),frame_device_big,stream=stream)</code> async kernel 1, frame 0 <br> <code>bgmog2.apply(frame_device_big, lr, stream, fg_device_big )</code> async kernel 2, frame 0<br> <code>cv.cuda.resize(fg_device_big,fg_device.size(),fg_device,stream=stream)</code> acync kernel 3, frame 0<br> <code>fg_device.download(stream,fg_host.array)</code> async copy DtoH, frame 0<br> <code>stream.queryIfComplete()</code> <strong>force WDDM to dispatch any qued device calls</strong><br> <code>ret,_ = cap.read(frame[1].array)</code> host read frame 1 <br> <code>stream.waitForCompletion()</code> block until kernel 1-3 and copy have finished for frame 0</p>
</blockquote>
</div>
</div>
</div>
<p><a id="gpu_5"></a></p>
</section>
</section>
<section id="overlap-host-and-device-computation-3" class="level1 page-columns page-full">
<h1>Overlap host and device computation (3)</h1>
<div class="cell" data-execution_count="81">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProcFrameCuda5:</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,rows_small,cols_small,rows_big,cols_big,store_res<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rows_small, <span class="va">self</span>.cols_small, <span class="va">self</span>.rows_big, <span class="va">self</span>.cols_big <span class="op">=</span> rows_small,cols_small,rows_big,cols_big</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.store_res <span class="op">=</span> store_res</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res <span class="op">=</span> []</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2 <span class="op">=</span> cv.cuda.createBackgroundSubtractorMOG2()</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream <span class="op">=</span> cv.cuda_Stream()</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_num <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_writable_mem <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frames_in <span class="op">=</span> [PinnedMem((rows_small,cols_small,<span class="dv">3</span>)),PinnedMem((rows_small,cols_small,<span class="dv">3</span>))]</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device <span class="op">=</span> cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3)</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device_big <span class="op">=</span> cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device <span class="op">=</span> cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC1)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_host <span class="op">=</span> PinnedMem((rows_small,cols_small))</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ProcessFrame(<span class="va">self</span>,lr):</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_num <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.frame_num <span class="op">&gt;</span> <span class="dv">1</span>):</span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.stream.waitForCompletion() <span class="co"># wait after we have read the next frame</span></span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fg_host.array))</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frame_device.upload(<span class="va">self</span>.frames_in[<span class="va">self</span>.i_writable_mem].array, <span class="va">self</span>.stream)</span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.frame_device, (cols_big,rows_big), <span class="va">self</span>.frame_device_big, stream<span class="op">=</span><span class="va">self</span>.stream)</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2.<span class="bu">apply</span>(<span class="va">self</span>.frame_device_big, lr, <span class="va">self</span>.stream, <span class="va">self</span>.fg_device_big )</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.fg_device_big, <span class="va">self</span>.fg_device.size(), <span class="va">self</span>.fg_device, stream<span class="op">=</span><span class="va">self</span>.stream)</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fg_device.download(<span class="va">self</span>.stream,<span class="va">self</span>.fg_host.array)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream.queryIfComplete() <span class="co"># kick WDDM</span></span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Frame(<span class="va">self</span>):</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_writable_mem <span class="op">=</span> (<span class="va">self</span>.i_writable_mem <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="bu">len</span>(<span class="va">self</span>.frames_in)</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.frames_in[<span class="va">self</span>.i_writable_mem].array</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Sync(<span class="va">self</span>):</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.stream.waitForCompletion()</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fg_host.array))</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>proc_frame_cuda5 <span class="op">=</span> ProcFrameCuda5(rows_small,cols_small,rows_big,cols_big,check_res)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="82">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>gpu_time_5, n_frames <span class="op">=</span> ProcVid2(proc_frame_cuda5,lr)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'GPU 5 (overlap host and device - attempt 3): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>gpu_time_5<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Incremental speedup: </span><span class="sc">{</span>gpu_time_4<span class="op">/</span>gpu_time_5<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over GPU baseline: </span><span class="sc">{</span>gpu_time_0<span class="op">/</span>gpu_time_5<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over CPU: </span><span class="sc">{</span>cpu_time_1<span class="op">/</span>gpu_time_5<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>GPU 5 (overlap host and device - attempt 3): 100 frames, 1.23 ms/frame
Incremental speedup: 1.49
Speedup over GPU baseline: 3.19
Speedup over CPU: 22.60</code></pre>
</div>
</div>
<p><a id="analysis_5"></a></p>
<section id="analysis-5" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="analysis-5">Analysis</h2>
<div class="column-screen">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/cudawarped/opencv-experiments/master/nbs/imgs/nvprof_6.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">title</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>It appears as though the WDDM driver was at fault, by including the extra call to <code>stream.queryIfComplete()</code> we have finally overlapped the processing on the host and device. This can be observed in the profiler output where the host time (~0.62ms), overlaps the device time (~0.79ms) in Stream 2017. Notice also that there are gaps between the blocks of device time in Stream 2017 with the runtime API time (~1.07ms) <strong>still</strong> starting sometime before the device time and ending exactly after the <code>Memcpy (DtoH)</code> (<code>fg_device.download(stream,fg_host.array)</code>).</p>
<p>Most importantly the device is almost saturated with only the small gap (~0.2ms) in between each block representing the device time for each frame in Stream 2017. So what is causing this small gap?</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypothesis
</div>
</div>
<div class="callout-body-container callout-body">
<p>The device is stalling.</p>
<p>As already mentioned the host time cannot be changed. Additionally from the profiler output it is clear that the host time (~0.62ms) is less than the device time (~0.79ms).</p>
<p>That is given the processing pipeline below &gt; <code>Process frame 0 on the device</code> <strong>~0.79ms</strong> (copy frame 0 to the device execute kernel 1-3 and copy back to the host)<br> <code>ret,_ = cap.read(frame[1].array)</code> <strong>~0.62ms</strong> (read frame 1 on the host) <br> <code>stream.waitForCompletion()</code> block for (<strong>~0.17ms</strong> = <sub>0.79ms-</sub>0.62ms) until processing for frame 0 has finished</p>
<p><code>stream.waitForCompletion()</code> will on average cause the host to wait ~0.17ms for the device processing to finish. This can be observed in the profiler output by the length of <code>cudaStreamchronize()</code> which for each frame ends exactly following the <code>Memcpy(DtoH)</code>. Unfortunately this wait stalls the device because it has no work to perform until more calls are issued by the host, which in this case does not occur until after the call to <code>stream.waitForCompletion()</code>. If only there was a way to issue work to the device in advance of <code>stream.waitForCompletion()</code>, which will continue to be performed afterwards.</p>
<p>Fortunately there is by using multiple streams, each processing a single frame at a time. This allows us to issue commands in advance, to process frame 1 before we start the wait on the host for frame 0, shown below</p>
<blockquote class="blockquote">
<p><code>ret,_ = cap.read(frame[0].array)</code>host read frame 0 <br> i)<code>Process frame 0 in stream 0</code><br> <code>ret,_ = cap.read(frame[1].array)</code>host read frame 1 <br> ii)<code>Process frame 1 in stream 1</code><br> <code>ret,_ = cap.read(frame[2].array)</code>host read frame 2 <br> <code>stream[0].waitForCompletion()</code> <strong>block until i) the processing for frame 0 has finished, allowing the device to continue with ii)</strong> <br> iii)<code>Process frame 2 in stream 0</code><br> <code>ret,_ = cap.read(frame[0].array)</code>host read frame 3 <br> <code>stream[1].waitForCompletion()</code> <strong>block until ii) the processing for frame 1 has finished, allowing the device to continue with iii)</strong><br> …</p>
</blockquote>
<p>Notice that when <code>stream[0].waitForCompletion()</code> is called the device has <code>Process frame 1 in stream 1</code> already queued up in stream 1 meaning that the wait on the host should not cause a stall on the device.</p>
<p><strong>Note:</strong> Using multiple streams in this way will add additional latency and is not going to be suitable for real time processing, that said the additional latency in most real world cases will be tolerable and worth the reduction in processing time.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Use multiple streams.</p>
</div>
</div>
</div>
<p><a id="gpu_6"></a></p>
</section>
</section>
<section id="overlap-host-and-device-computation---multiple-streams" class="level1 page-columns page-full">
<h1>Overlap host and device computation - multiple streams</h1>
<div class="cell" data-execution_count="84">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SyncType():</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>    none <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    soft <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    hard <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ProcFrameCuda6:</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,rows_small,cols_small,rows_big,cols_big,n_streams,store_res<span class="op">=</span><span class="va">False</span>,sync<span class="op">=</span>SyncType.soft,device_timer<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.rows_small, <span class="va">self</span>.cols_small, <span class="va">self</span>.rows_big, <span class="va">self</span>.cols_big <span class="op">=</span> rows_small,cols_small,rows_big,cols_big</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_streams <span class="op">=</span> n_streams</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.store_res <span class="op">=</span> store_res        </span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sync <span class="op">=</span> sync</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2 <span class="op">=</span> cv.cuda.createBackgroundSubtractorMOG2()</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frames_device <span class="op">=</span> []</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frames_device_big <span class="op">=</span> []</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fgs_device_big <span class="op">=</span> []</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fgs_device <span class="op">=</span> []</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fgs_small <span class="op">=</span> []   </span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.streams <span class="op">=</span> []</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frames <span class="op">=</span> []</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.InitMem()</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.InitStreams()</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.res <span class="op">=</span> []</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_stream <span class="op">=</span> <span class="dv">0</span>        </span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_frames <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_writable_mem <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device_timer <span class="op">=</span> device_timer</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.device_timer:</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.events_start <span class="op">=</span> []</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.events_stop <span class="op">=</span> []</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.InitEvents()</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.device_time <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> InitMem(<span class="va">self</span>):</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="va">self</span>.n_streams <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.frames.append(PinnedMem((rows_small,cols_small,<span class="dv">3</span>)))</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="va">self</span>.n_streams):</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.frames_device.append(cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC3))</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.frames_device_big.append(cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC3))</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.fgs_device_big.append(cv.cuda_GpuMat(rows_big,cols_big,cv.CV_8UC1))</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.fgs_device.append(cv.cuda_GpuMat(rows_small,cols_small,cv.CV_8UC1))</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.fgs_small.append(PinnedMem((rows_small,cols_small)))</span>
<span id="cb31-44"><a href="#cb31-44" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb31-45"><a href="#cb31-45" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> InitStreams(<span class="va">self</span>):</span>
<span id="cb31-46"><a href="#cb31-46" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="va">self</span>.n_streams): </span>
<span id="cb31-47"><a href="#cb31-47" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.sync <span class="op">==</span> SyncType.hard:</span>
<span id="cb31-48"><a href="#cb31-48" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.streams.append(cv.cuda.Stream_Null())</span>
<span id="cb31-49"><a href="#cb31-49" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="va">self</span>.sync <span class="op">==</span> SyncType.soft:</span>
<span id="cb31-50"><a href="#cb31-50" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.streams.append(cv.cuda_Stream())</span>
<span id="cb31-51"><a href="#cb31-51" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb31-52"><a href="#cb31-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> InitEvents(<span class="va">self</span>):</span>
<span id="cb31-53"><a href="#cb31-53" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="va">self</span>.n_streams):</span>
<span id="cb31-54"><a href="#cb31-54" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.events_start.append(cv.cuda_Event())</span>
<span id="cb31-55"><a href="#cb31-55" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.events_stop.append(cv.cuda_Event()) </span>
<span id="cb31-56"><a href="#cb31-56" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb31-57"><a href="#cb31-57" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> IncStream(<span class="va">self</span>):</span>
<span id="cb31-58"><a href="#cb31-58" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_stream <span class="op">=</span> (<span class="va">self</span>.i_stream<span class="op">+</span><span class="dv">1</span>)<span class="op">%</span><span class="va">self</span>.n_streams</span>
<span id="cb31-59"><a href="#cb31-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-60"><a href="#cb31-60" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> ProcessFrame(<span class="va">self</span>,lr):</span>
<span id="cb31-61"><a href="#cb31-61" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_frames <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb31-62"><a href="#cb31-62" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> <span class="va">self</span>.i_stream</span>
<span id="cb31-63"><a href="#cb31-63" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.IncStream()</span>
<span id="cb31-64"><a href="#cb31-64" aria-hidden="true" tabindex="-1"></a>        stream <span class="op">=</span> <span class="va">self</span>.streams[i]</span>
<span id="cb31-65"><a href="#cb31-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(<span class="va">self</span>.n_frames <span class="op">&gt;</span> <span class="va">self</span>.n_streams <span class="kw">and</span> <span class="va">self</span>.sync <span class="op">!=</span> SyncType.none):            </span>
<span id="cb31-66"><a href="#cb31-66" aria-hidden="true" tabindex="-1"></a>            stream.waitForCompletion() <span class="co"># wait once both streams are used               </span></span>
<span id="cb31-67"><a href="#cb31-67" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.device_timer:  <span class="va">self</span>.device_time <span class="op">+=</span> cv.cuda_Event.elapsedTime(<span class="va">self</span>.events_start[i],<span class="va">self</span>.events_stop[i])</span>
<span id="cb31-68"><a href="#cb31-68" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb31-69"><a href="#cb31-69" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fgs_small[i].array))</span>
<span id="cb31-70"><a href="#cb31-70" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.device_timer: <span class="va">self</span>.events_start[i].record(stream)</span>
<span id="cb31-71"><a href="#cb31-71" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.frames_device[i].upload(<span class="va">self</span>.frames[<span class="va">self</span>.i_writable_mem].array,stream)</span>
<span id="cb31-72"><a href="#cb31-72" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.frames_device[i], (cols_big,rows_big), <span class="va">self</span>.frames_device_big[i], stream<span class="op">=</span>stream)</span>
<span id="cb31-73"><a href="#cb31-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.bgmog2.<span class="bu">apply</span>(<span class="va">self</span>.frames_device_big[i], lr, stream, <span class="va">self</span>.fgs_device_big[i])</span>
<span id="cb31-74"><a href="#cb31-74" aria-hidden="true" tabindex="-1"></a>        cv.cuda.resize(<span class="va">self</span>.fgs_device_big[i], <span class="va">self</span>.fgs_device[i].size(), <span class="va">self</span>.fgs_device[i], stream<span class="op">=</span>stream)</span>
<span id="cb31-75"><a href="#cb31-75" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fgs_device[i].download(stream, <span class="va">self</span>.fgs_small[i].array)</span>
<span id="cb31-76"><a href="#cb31-76" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.device_timer: <span class="va">self</span>.events_stop[i].record(stream)</span>
<span id="cb31-77"><a href="#cb31-77" aria-hidden="true" tabindex="-1"></a>        stream.queryIfComplete() <span class="co"># kick WDDM       </span></span>
<span id="cb31-78"><a href="#cb31-78" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-79"><a href="#cb31-79" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Frame(<span class="va">self</span>):</span>
<span id="cb31-80"><a href="#cb31-80" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.i_writable_mem <span class="op">=</span> (<span class="va">self</span>.i_writable_mem <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="bu">len</span>(<span class="va">self</span>.frames)</span>
<span id="cb31-81"><a href="#cb31-81" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.frames[<span class="va">self</span>.i_writable_mem].array</span>
<span id="cb31-82"><a href="#cb31-82" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-83"><a href="#cb31-83" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> Sync(<span class="va">self</span>):</span>
<span id="cb31-84"><a href="#cb31-84" aria-hidden="true" tabindex="-1"></a>        <span class="co"># sync on last frames</span></span>
<span id="cb31-85"><a href="#cb31-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> (<span class="va">self</span>.sync <span class="op">==</span> SyncType.none):</span>
<span id="cb31-86"><a href="#cb31-86" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span></span>
<span id="cb31-87"><a href="#cb31-87" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb31-88"><a href="#cb31-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>,<span class="va">self</span>.n_streams):</span>
<span id="cb31-89"><a href="#cb31-89" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span>(<span class="kw">not</span> <span class="va">self</span>.streams[<span class="va">self</span>.i_stream].queryIfComplete()):</span>
<span id="cb31-90"><a href="#cb31-90" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.streams[<span class="va">self</span>.i_stream].waitForCompletion()</span>
<span id="cb31-91"><a href="#cb31-91" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span>(<span class="va">self</span>.store_res):</span>
<span id="cb31-92"><a href="#cb31-92" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.res.append(np.copy(<span class="va">self</span>.fgs_small[<span class="va">self</span>.i_stream].array))</span>
<span id="cb31-93"><a href="#cb31-93" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.IncStream()        </span>
<span id="cb31-94"><a href="#cb31-94" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb31-95"><a href="#cb31-95" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> FrameTimeMs(<span class="va">self</span>):</span>
<span id="cb31-96"><a href="#cb31-96" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.device_timer:</span>
<span id="cb31-97"><a href="#cb31-97" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.device_time<span class="op">/</span><span class="va">self</span>.n_frames</span>
<span id="cb31-98"><a href="#cb31-98" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb31-99"><a href="#cb31-99" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="dv">0</span></span>
<span id="cb31-100"><a href="#cb31-100" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb31-101"><a href="#cb31-101" aria-hidden="true" tabindex="-1"></a>proc_frame_cuda6 <span class="op">=</span> ProcFrameCuda6(rows_small,cols_small,rows_big,cols_big,<span class="dv">2</span>,check_res,SyncType.soft)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution_count="85">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>gpu_time_6, n_frames <span class="op">=</span> ProcVid2(proc_frame_cuda6,lr)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'GPU 6 (multiple streams): </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames, </span><span class="sc">{</span>gpu_time_6<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Incremental speedup: </span><span class="sc">{</span>gpu_time_5<span class="op">/</span>gpu_time_6<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over GPU baseline: </span><span class="sc">{</span>gpu_time_0<span class="op">/</span>gpu_time_6<span class="sc">:.2f}</span><span class="ss">'</span>)</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Speedup over CPU: </span><span class="sc">{</span>cpu_time_1<span class="op">/</span>gpu_time_6<span class="sc">:.2f}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>GPU 6 (multiple streams): 100 frames, 0.97 ms/frame
Incremental speedup: 1.27
Speedup over GPU baseline: 4.05
Speedup over CPU: 28.68</code></pre>
</div>
</div>
<p><a id="analysis_6"></a></p>
<section id="analysis-6" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="analysis-6">Analysis</h2>
<div class="column-screen">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://raw.githubusercontent.com/cudawarped/opencv-experiments/master/nbs/imgs/nvprof_7.PNG" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">title</figcaption>
</figure>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The device is now completely saturated with memory operations overlapping kernel executions in Streams 2418 and 2419. Additionally the host and device time completely overlap each other. By saturating the device and overlapping host and device computation we have probably reached the limit of the optimizations we can apply to this particular toy problem.</p>
<p>Notice that as a result of the kernel/memory overlap the average device time is no longer equal to the average amount of time to process a frame on the device (streamed device time). In fact because of kernel/memory and host/device overlap the average device time should now be greater than both the average streamed device and frame time.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Hypothesis
</div>
</div>
<div class="callout-body-container callout-body">
<p>If the above assumption is correct we should be able to see this effect by using device timers to get a more accurate value for the average device time.</p>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Next
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Use device timers to get the average device time. Unfortunately this introduces some overhead so we will have to compare this to the average time required to process each frame calculated without the device timers. This may mean that we may not see the difference that we expect.</li>
<li>Calculate the theoretical average time to process each frame on the host and then the device without overlap (host time + device time), to see the gain from host/device and kernel/memory overlap.</li>
<li>Calculate the average wasted time on the host (streamed device time - host time) time where the host could be performing useful operations without increasing the average processing time).</li>
</ol>
</div>
</div>
</div>
<p><a id="without_profiler"></a></p>
</section>
</section>
<section id="timing-without-the-profiler" class="level1">
<h1>Timing without the profiler</h1>
<div class="cell" data-execution_count="94">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co">#export</span></span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>proc_frame_cuda7 <span class="op">=</span> ProcFrameCuda6(rows_small,cols_small,rows_big,cols_big,<span class="dv">2</span>,check_res,SyncType.soft,<span class="va">True</span>)</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>ProcVid2(proc_frame_cuda7,lr)</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Mean times calculated over </span><span class="sc">{</span>n_frames<span class="sc">}</span><span class="ss"> frames:'</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Time to process each frame on the device: </span><span class="sc">{</span>proc_frame_cuda7<span class="sc">.</span>FrameTimeMs()<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Time to process each frame (host/device): </span><span class="sc">{</span>gpu_time_6<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'-&gt; Gain from memcpy/kernel overlap if device is saturated: </span><span class="sc">{</span>proc_frame_cuda7<span class="sc">.</span>FrameTimeMs()<span class="op">-</span>gpu_time_6<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>hostTime, n_frames <span class="op">=</span> ProcVid2(proc_frame_cuda6, lr, <span class="va">True</span>)</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Time to read and decode each frame on the host: </span><span class="sc">{</span>hostTime<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'-&gt; Total processing time host + device: </span><span class="sc">{</span>proc_frame_cuda7<span class="sc">.</span>FrameTimeMs()<span class="op">+</span>hostTime<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'-&gt; Gain from host/device overlap: </span><span class="sc">{</span>proc_frame_cuda7<span class="sc">.</span>FrameTimeMs()<span class="op">+</span>hostTime <span class="op">-</span> gpu_time_6<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'-&gt; Currently waisted time on host: </span><span class="sc">{</span>gpu_time_6<span class="op">-</span>hostTime<span class="sc">:.2f}</span><span class="ss"> ms/frame'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Mean times calculated over 100 frames:
Time to process each frame on the device: 1.00 ms/frame
Time to process each frame (host/device): 0.97 ms/frame
-&gt; Gain from memcpy/kernel overlap if device is saturated: 0.04 ms/frame
Time to read and decode each frame on the host: 0.71 ms/frame
-&gt; Total processing time host + device: 1.71 ms/frame
-&gt; Gain from host/device overlap: 0.74 ms/frame
-&gt; Currently waisted time on host: 0.26 ms/frame</code></pre>
</div>
</div>
<p><a id="analysis_7"></a></p>
<section id="analysis-7" class="level2">
<h2 class="anchored" data-anchor-id="analysis-7">Analysis</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Observations
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ol type="1">
<li>It appears that we gained 0.04 ms/frame from the kernel/memory processing overlap on the device. Unfortunately we cannot say this for sure because the times compared here are from two separate runs due to the device timer overhead. That said, the implication is that our interpretation of the kernel/memory overlap seen in the Nvidia Visual Profiler is correct.</li>
<li>The total processing which needs to be performed on the host and device takes and average of 1.71 ms/frame which is 0.74 ms/frame greater than our final implementation, demonstrating the importance of using asynchronous device calls and CUDA streams.</li>
<li>We have 0.26 ms/frame to spare on the host which we can make use of without affecting the average frame time of 0.97 ms/frame.</li>
</ol>
</div>
</div>
</div>
<p><a id="summary"></a></p>
</section>
</section>
<section id="summary" class="level1">
<h1>Summary</h1>
<p>When calling OpenCV CUDA functions the most effective optimizations (in order of effectiveness/ease to implement) for this toy problem are given below. Whilst (1) will always be effective, the other optimizations will heavily depend on the CPU/GPU specifications, data size and the amount of processing which can be performed on the device before returning to the host. Therefore it is always beneficial to use a tool such as the Nvidia visual profiler to analyze your pipeline as you make changes. 1. Pre-allocate and pass all Numpy and/or GpuMat arrays (making sure they are the correct size) as function arguments to avoid them being allocated each time the function is called. 2. Try to design a processing pipeline which allows memory copies to overlap kernel calls and work to be performed on both the host and the device at the same time. 3. Use CUDA streams with pinned host memory and if you are working on windows consider calling <code>stream.queryIfComplete()</code> to force the WDDM driver to dispatch the CUDA calls. 4. Use multiple streams.</p>
<p><a id="export"></a></p>
<section id="run-outside-the-notebook" class="level3">
<h3 class="anchored" data-anchor-id="run-outside-the-notebook">Run outside the notebook</h3>
<div class="cell" data-execution_count="4">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># taken from https://github.com/fastai/fastai_docs/blob/master/dev_nb/notebook2script.py</span></span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>python notebook2script.py <span class="st">"opencv4-cuda-streams.ipynb"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Converted opencv4-cuda-streams.ipynb to exp\nb_opencv4-cuda-streams.py</code></pre>
</div>
</div>
<div class="cell" data-execution_count="9">
<details open="">
<summary>Expand to inspect the source code</summary>
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> python exp<span class="op">/</span>nb_opencv4<span class="op">-</span>cuda<span class="op">-</span>streams.py</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>CPU 0 (naive): 100 frames, 29.74 ms/frame
GPU 0 (naive): 100 frames, 9.06 ms/frame
Speedup over CPU: 3.28
CPU 1 (pre-allocation): 100 frames, 27.59 ms/frame
Speedup over CPU baseline: 1.08
GPU 1 (pre-allocation): 100 frames, 1.93 ms/frame
Incremental speedup: 4.69
Speedup over CPU: 14.29
GPU 2 (replacing the default stream): 100 frames, 1.82 ms/frame
Incremental speedup: 1.06
Speedup over GPU baseline: 4.99
Speedup over CPU: 15.18
GPU 3 (overlap host and device - attempt 1): 100 frames, 1.72 ms/frame
Incremental speedup: 1.06
Speedup over GPU baseline: 5.28
Speedup over CPU: 16.06
GPU 4 (overlap host and device - attempt 2): 100 frames, 1.72 ms/frame
Incremental speedup: 1.00
Speedup over GPU baseline: 5.27
Speedup over CPU: 16.03
GPU 5 (overlap host and device - attempt 3): 100 frames, 1.11 ms/frame
Incremental speedup: 1.55
Speedup over GPU baseline: 8.17
Speedup over CPU: 24.88
GPU 6 (multiple streams): 100 frames, 0.90 ms/frame
Incremental speedup: 1.23
Speedup over GPU baseline: 10.03
Speedup over CPU: 30.54
Mean times calculated over 100 frames:
Time to process each frame on the device: 0.93 ms/frame
Time to process each frame (host/device): 0.90 ms/frame
-&gt; Gain from memcpy/kernel overlap if device is saturated: 0.03 ms/frame
Time to read and decode each frame on the host: 0.65 ms/frame
-&gt; Total processing time host + device: 1.58 ms/frame
-&gt; Gain from host/device overlap: 0.68 ms/frame
-&gt; Currently waisted time on host: 0.26 ms/frame
[ INFO:0] global E:\Dev\Repos\opencv_fork_1\modules\videoio\src\videoio_registry.cpp (187) cv::`anonymous-namespace'::VideoBackendRegistry::VideoBackendRegistry VIDEOIO: Enabled backends(7, sorted by priority): FFMPEG(1000); GSTREAMER(990); INTEL_MFX(980); MSMF(970); DSHOW(960); CV_IMAGES(950); CV_MJPEG(940)</code></pre>
</div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("https:\/\/cudawarped\.github\.io\/opencv-experiments\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>